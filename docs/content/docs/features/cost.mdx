---
title: Cost Metadata
summary: Documentation on the cost metadata returned by the API. Explains how estimated costs are provided for each request and how to access this data programmatically.
---

import { Tabs, Tab } from 'fumadocs-ui/components/tabs';

While most standard LLM APIs return usage metrics (like input and output token counts), they typically don't provide the actual monetary cost of the request. Developers are often left to calculate this themselves, requiring them to maintain and apply up-to-date pricing information for each model.

AnotherAI simplifies cost tracking by automatically calculating the estimated cost for each LLM request based on the specific model used and AnotherAI's current pricing data.

### Programmatically

The cost and latency information are added to each choice in the response:

<Tabs items={["OpenAI SDK (Python)", "OpenAI SDK (JavaScript)", "REST API", "Instructor (Python)"]}>
  <Tab>
  ```python
  import openai

  client = openai.OpenAI(
      api_key="YOUR_ANOTHERAI_API_KEY",
      base_url="{{API_URL}}/v1"
  )

  completion = client.chat.completions.create(
      model="gpt-4o-mini",
      messages=[{"role": "user", "content": "Hello!"}],
      metadata={"agent_id": "my-agent"}
  )

  # Access cost and latency from the first choice
  cost = getattr(completion.choices[0], 'cost_usd', None)
  latency = getattr(completion.choices[0], 'duration_seconds', None)

  print(f"Cost: ${cost:.6f}")
  print(f"Latency: {latency:.2f}s")
  ```
  </Tab>
  <Tab>
  ```javascript
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: 'YOUR_ANOTHERAI_API_KEY',
    baseURL: '{{API_URL}}/v1',
  });

  const completion = await client.chat.completions.create({
    model: 'gpt-4o-mini',
    messages: [{ role: 'user', content: 'Hello!' }],
    metadata: { agent_id: 'my-agent' }
  });

  // Access cost and latency from the first choice
  const cost = completion.choices[0].cost_usd;
  const latency = completion.choices[0].duration_seconds;

  console.log(`Cost: $${cost.toFixed(6)}`);
  console.log(`Latency: ${latency.toFixed(2)}s`);
  ```
  </Tab>
  <Tab>
  ```bash
  curl {{API_URL}}/v1/chat/completions \
    -H "Authorization: Bearer YOUR_ANOTHERAI_API_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "model": "gpt-4o-mini",
      "messages": [{"role": "user", "content": "Hello!"}],
      "metadata": {"agent_id": "my-agent"}
    }'

  # Response includes cost_usd and duration_seconds in each choice:
  # {
  #   "choices": [{
  #     "message": {...},
  #     "cost_usd": 0.000015,
  #     "duration_seconds": 1.23
  #   }],
  #   ...
  # }
  ```
  </Tab>
  <Tab>
  ```python
  from pydantic import BaseModel
  import instructor

  client = instructor.from_openai(
      openai.OpenAI(
          api_key="YOUR_ANOTHERAI_API_KEY",
          base_url="{{API_URL}}/v1"
      )
  )

  class Answer(BaseModel):
      sentiment: str
      score: float

  answer, completion = client.chat.completions.create_with_completion(
      model="gpt-4o-mini",
      response_model=Answer,
      messages=[{"role": "user", "content": "I love AnotherAI!"}],
      metadata={"agent_id": "sentiment-analysis-agent"}
  )

  # Access cost and latency from the completion
  cost = getattr(completion.choices[0], 'cost_usd', None)
  latency = getattr(completion.choices[0], 'duration_seconds', None)

  print(f"Sentiment: {answer.sentiment}, Score: {answer.score}")
  print(f"Cost: ${cost:.6f}, Latency: {latency:.2f}s")
  ```
  </Tab>
</Tabs>

## Tracking Costs

### Via MCP

Ask questions about costs in natural language using your preferred AI assistant:

```
What's the total cost for my-agent since January 1st, 2024?
```

```
Show me the sum of all costs for my-agent completions created after 2024-01-01
```


### Creating Cost Views in AnotherAI

Track spending across agents with custom views:

`Create a view in AnotherAI that shows daily costs for calendar_event_extractor.py`

`Create a view showing total monthly spend across all agents, by agent_id, with a line chart`

`Create a cost breakdown view showing spend by model across all agents`
