---
title: Overview
summary: Introduction to the AnotherAI documentation. Provides information on what AnotherAI is and how to get started with building, deploying, and improving AI agents.
---

import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';
import { Step, Steps } from 'fumadocs-ui/components/steps';
import { Code2, BookOpen, Wand2, Eye, Network, FileCode, Shield } from 'lucide-react';

## What is AnotherAI?

**AnotherAI turns your AI coding assistant into your AI engineer.**

Claude Code, Cursor, and Windsurf operate your AI agents through MCP. Compatible with any programming language and SDK (OpenAI, Vercel AI, PydanticAI, Instructor), access every LLM model from: OpenAI, Anthropic, Google, Meta, DeepSeek, Mistral, and more. Fully [open-source](https://github.com/anotherai-dev/anotherai).

**What your AI engineer can do:**
- **Debug production issues:** "Why is the email parser failing?" → Queries logs, identifies patterns, deploys fix
- **Run experiments:** "Compare GPT-4o vs Claude Sonnet 4 on accuracy and cost" → A/B tests models and prompts with production data
- **Deploy without code changes:** "Make the support bot more concise" → Updates prompts instantly, no PR needed
- **Optimize costs:** "Reduce AI spend by 30%" → Analyzes usage, switches to cheaper models where quality permits
- **Improve from feedback:** "Analyze user feedback for the invoice parser" → Reviews collected feedback, identifies issues, suggests prompt improvements
- **Analyze performance:** "Show response times by model this week" → Generates custom metrics and visualizations
- **Evaluate quality:** "Test if the new prompt maintains accuracy" → Runs evaluation suites, compares against baselines

{/* Watch Claude Code debug an issue with an agent and deploy a fix without changing the codebase:
[video] */}

<Callout type="info" href="/pricing">
By using AnotherAI, you won't pay more than your current inference costs. We price match the providers and make our margin through volume discounts. [Learn more about our pricing](/pricing).
</Callout>

## Get Started

### Set Up

To use AnotherAI's hosted service: go to [https://anotherai.dev/](https://anotherai.dev/) and sign up to create a free account.
<Callout>
Are you interested in a self-hosted, [open-source](https://github.com/anotherai-dev/anotherai) set up? We have that too! You can learn how to get set up [here](/self-hosted). 
</Callout>

### MCP 

AnotherAI is available as an MCP server in the IDEs below.

<Tabs items={['Cursor', 'Claude Code', 'Windsurf', 'Cursor CLI']}>

<Tab value="Cursor">

1. Open Cursor
2. Go to `Settings...`
3. Navigate to `Cursor Settings`
4. Select `Tools and Integrations`
5. Select `+ New MCP Server`

Add the following configuration to your MCP servers config:

```json
{
  "mcpServers": {
    "anotherai": {
      "url": "{{API_URL}}/mcp",
      "headers": {
        "Authorization": "Bearer <your_api_key_here>"
      }
    }
  }
}
```

Cursor UI should now look like this (note the green indicator and the number of tools enabled displayed):

![Successful Cursor MCP Server Setup](/images/mcp/cursor-setup-ok.png)

</Tab>

<Tab value="Claude Code">

  1. Complete the set up above
  2. Get your API key on [anotherai.dev/](https://anotherai.dev/completions?showManageKeysModal=true) 
  3. Open Claude Code in your preferred terminal (standalone or within your IDE).
  4. Type the following to install:

  ```bash
  claude mcp add --scope user anotherai {{API_URL}}/mcp --transport http --header "Authorization: Bearer YOUR_API_KEY_HERE"
  ```

  <Callout type="info">
  **Installation Scopes**: The `--scope user` flag installs AnotherAI for your personal use across all projects. For team projects, you can use `--scope project` instead to create a shared `.mcp.json` file that can be committed to version control and shared with your team members. Learn more about MCP scopes in the [Anthropic documentation](https://docs.anthropic.com/en/docs/claude-code/mcp#user-scope).
  </Callout>

  5. Type the following to verify the server is properly connected:

  ```bash
claude
```

Then type:
```bash
/mcp 
```

You should see the AnotherAI server listed as "connected".

</Tab>

<Tab value="Windsurf">

1. Open Windsurf
2. Go to `Settings...`
3. Select `Windsurf Settings`
4. Navigate to `Cascade`
5. Select `Manage MCPs`
6. Select `View Raw Config`

Add the following configuration to your MCP servers config:

```json
{
  "mcpServers": {
    "anotherai": {
      "url": "{{API_URL}}/mcp",
      "headers": {
        "Authorization": "Bearer <your_api_key_here>"
      }
    }
  }
}
```

Navigate back to Manage MCPs and refresh the page. The AnotherAI MCP should appear and show as enabled.

</Tab>

<Tab value="Cursor CLI">

Cursor CLI can access MCPs configured in your IDE's  `mcp.json` configuration file, enabling the same MCP servers and tools that you've configured for the IDE.

Setup steps:

1. Complete the [set up](#set-up) steps described above and ensure the AnotherAI MCP server is running
2. Configure the AnotherAI MCP in your IDE's `mcp.json` file, as described in the `Cursor` tab.
3. Once the MCP is enabled and active, you can ask the Cursor CLI to interact with it

<Callout type="info">
**Additional Configuration**: If you find that the CLI claims it can't find or use the AnotherAI MCP, you may need to give it the specific file path to use to look for the mcp.json file.
</Callout>

</Tab>

</Tabs>

### Try it out

After you have the above set up completed, AnotherAI is ready to use!

- If you have agents already created, check out how to [migrate them to AnotherAI](/agents/migrating).

- If you don't have any agents built yet, check out [building a new agent](/agents/building) to learn about building a new AnotherAI-compatible agent.


Once you have an agent built or migrated, here are some examples of prompts you can send to Claude Code to test how AnotherAI works:

```bash
Create an experiment in AnotherAI that compares how GPT-5 mini and GPT-4 mini perform on @[your-agent-name-here].
```
```bash
Use AnotherAI to help me find a faster model for @[your-agent-name-here] while still maintaining accuracy.
```

### AnotherAI's Zero Lock-in Promise

**It's easier to leave AnotherAI than to leave OpenAI directly.**

To switch away from AnotherAI:
- Remove `base_url="{{API_URL}}/v1"`
- If you're not using deployments: your code stays identical
- If you are using deployments: simply ask Claude Code (or your preferred coding agent) to fetch your deployment configuration (static content and model) and recreate the equivalent configuration in your code.

While using AnotherAI, you:
- Get automatic fallbacks across providers
- Collect valuable performance data about your AI usage  
- Can export everything when/if you leave

We built AnotherAI this way because we've been burned by vendor lock-in too. The OpenAI-compatible design isn't just about easy onboarding - it's about respecting your right to walk away.

**Bottom line:** Try AnotherAI risk-free. If it doesn't provide value, switching back takes minutes, not months.

## Join the community

If you have questions about AnotherAI, reach out to our team and community on our community [Slack](https://join.slack.com/t/anotherai-dev/shared_invite/zt-3av2prezr-Lz10~8o~rSRQE72m_PyIJA).
