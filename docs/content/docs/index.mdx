---
title: Overview
summary: Introduction to the AnotherAI documentation. Provides information on what AnotherAI is and how to get started with building, deploying, and improving AI agents.
---

import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';
import { Step, Steps } from 'fumadocs-ui/components/steps';
import { Code2, BookOpen, Wand2, Eye, Network, FileCode, Shield } from 'lucide-react';

## What is AnotherAI?

**AnotherAI turns your AI coding assistant into your AI engineer.**

Let Claude Code, Cursor, and Windsurf operate your AI agents through MCP. Compatible with any programming language and SDK (OpenAI, Vercel AI, PydanticAI, Instructor), access every LLM model from: OpenAI, Anthropic, Google, Meta, DeepSeek, Mistral, and more. Fully [open-source](https://github.com/anotherai-dev/anotherai).

**With AnotherAI, your coding assistant becomes an AI engineer that can:**
- **[Build new agents](/use-cases/building):** Tests [100+ models](/features/models) from OpenAI, Anthropic, Google & more, optimizes prompts, compares quality vs. cost vs. speed
```bash
Create an AI agent to classify customer support messages with less than 1s latency.
```
- **[Debug production issues](/use-cases/debugging):** `Why is the email parser failing?` → Queries logs, identifies patterns, deploys fix
- **[Run experiments](/use-cases/checking-new-models):** "Compare GPT-4o vs Claude 3.5 on accuracy and cost" → A/B tests models and prompts with production data
- **[Deploy without code changes](/use-cases/code-free-updates):** "Make the support bot more concise" → Updates prompts instantly, no PR needed
- **[Optimize costs](/use-cases/lowering-costs):** "Reduce AI spend by 30%" → Analyzes usage, switches to cheaper models where quality permits
- **[Improve from feedback](/use-cases/user-feedback):** "Analyze user feedback for the invoice parser" → Reviews collected feedback, identifies issues, suggests prompt improvements
- **[Analyze performance](/use-cases/metrics):** "Show response times by model this week" → Generates custom metrics and visualizations
- **[Evaluate quality](/use-cases/evaluating):** "Test if the new prompt maintains accuracy" → Runs evaluation suites, compares against baselines

{/* Watch Claude Code debug an issue with an agent and deploy a fix without changing the codebase:
[video] */}

<Callout type="info" href="/pricing">
By using AnotherAI, you won't pay more than your current inference costs. We price match the providers and make our margin through volume discounts. [Learn more about our pricing](/pricing).
</Callout>

## Join the community

If you have questions about AnotherAI, reach out to our team and community on our community [Slack](https://join.slack.com/t/anotherai-dev/shared_invite/zt-3av2prezr-Lz10~8o~rSRQE72m_PyIJA).
