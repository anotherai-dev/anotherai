---
title: Cost Metadata
summary: Documentation on the cost metadata returned by the API. Explains how estimated costs are provided for each request and how to access this data programmatically.
---

import { Tabs, Tab } from 'fumadocs-ui/components/tabs';

While most standard LLM APIs return usage metrics (like input and output token counts), they typically don't provide the actual monetary cost of the request. Developers are often left to calculate this themselves, requiring them to maintain and apply up-to-date pricing information for each model.

AnotherAI simplifies cost tracking by automatically calculating the estimated cost for each LLM request based on the specific model used and AnotherAI's current pricing data.

### Programmatically

TODO:
- adjust the code for this section, the cost and latency are inside the array choices[]
- add AnotherAI SDK and REST API examples

<Tabs items={["curl", "OpenAI SDK (Python)", "OpenAI SDK (Ruby)", "Instructor (Python)"]}>
  <Tab>
  ```
  ....
  ```
  </Tab>
  <Tab>
  ```python
  class Answer(BaseModel):
      sentiment: str
      score: float

  answer, completion = client.chat.completions.create_with_completion(
      model="gpt-4o-mini",
      response_model=Answer,
      messages=[{"role": "user", "content": "I love Workflow AI!"}],
      metadata={"agent_id": "sentiment-analysis-agent"}
  )

  cost = getattr(completion.choices[0], 'cost_usd', None)
  latency = getattr(completion.choices[0], 'duration_seconds', None)
  ```
  </Tab>
  <Tab>
  ```ruby
  # Ruby implementation here
  ...
  ```
  </Tab>
  <Tab>
  ```python
  # Instructor implementation here
  ...
  ```
  </Tab>
</Tabs>

#### ...

<Callout type="info">
  You can also track costs in the [Playground](/playground) and the [Monitor](/observability) sections.
</Callout>

TODO: add a section on how to track costs via the API and MCP.
