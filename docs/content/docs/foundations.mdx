---
title: Foundations
summary: Essential concepts and architecture of AnotherAI to get you started with agents, models, deployments, and core features.
---

## What is AnotherAI?

Think of AnotherAI as a drop-in replacement for OpenAI API, with primitives added to make it easier to build AI agents.

AnotherAI works with all programming languages, we provide specific examples for Python, Javascript, Typescript, Go, Ruby, Rust, Java, C#.

### Cost 

By using AnotherAI, you won't pay more than your current inference costs. We price match the providers and make our margin through volume discounts. [Learn more about our pricing](/pricing).

## Primitives

### Inference

AnotherAI exposes a compatible OpenAI API endpoint to `/v1/chat/completions`, which means that all SDKs that support OpenAI API will work with AnotherAI by simply changing the base URL and the API key.

> The API Key is usually stored in an environment variable (e-g `ANOTHERAI_API_KEY`). AnotherAI API keys start with `aai-...`. API Keys can be created in the UI or using the `create_api_key` MCP tool.

<Tabs groupId="framework" items={['Python (OpenAI SDK)', 'TypeScript (OpenAI SDK)', 'Go (OpenAI SDK)']}>
<Tab value="Python (OpenAI SDK)">
```python
import openai

client = openai.OpenAI(
    base_url="{{API_URL}}/v1",
    api_key="aai-***", 
)
```
</Tab>
<Tab value="TypeScript (OpenAI SDK)">
```typescript
import OpenAI from 'openai';

const client = new OpenAI({
    baseURL: '{{API_URL}}/v1',
    apiKey: 'aai-***', 
})
```
</Tab>
<Tab value="Go (OpenAI SDK)">
```go
import (
	"github.com/openai/openai-go/v2"
	"github.com/openai/openai-go/v2/option"
)

var client = openai.NewClient(
	option.WithBaseURL("{{API_URL}}/v1"),
	option.WithAPIKey("aai-***"),
)
```
</Tab>
</Tabs>

The primary benefit of using AnotherAI's API is gaining access to a unified interface for all AI models across the market. The list of models supported can be listed by calling the `list_models` MCP tool, or `curl {{API_URL}}/v1/models`. This eliminates the complexity of managing multiple API keys and switching between different provider SDKs - you can seamlessly use any model through a single, consistent API.

Technical details:
- all requests are proxied by AnotherAI, then sent to an AI provider.

### API

You can interact with the API directly, read the [OpenAPI spec]({{API_URL}}/openapi.json)

### Observability

By default, AnotherAI saves all LLM completions. Observability is critical for building reliable AI agents. LLM observability helps teams improve reliability, reduce costs, debug failures faster, ensure safety, and optimize prompts and models by providing end-to-end visibility into how queries are processed and where issues arise.

#### Viewing Completions in the Web App

To view your completions in the AnotherAI web app, use the `query_completions` MCP tool. This tool validates your SQL query and returns a URL to view the results in the web interface.

Learn more about by reading the [Observability](/observability) section.

### Experiments

Experiments are containers for testing and comparing different model configurations, prompts, and parameters. They enable systematic evaluation and iteration of AI agents.

**Key concepts:**
- Experiments group related completions for analysis
- Each experiment has a unique ID and can be annotated with feedback
- Results are documented for future reference and learning

**Creating experiments with the playground tool:**
The `playground` tool enables systematic testing across multiple dimensions:
- Test multiple models in parallel (e.g., "gpt-4o-mini,claude-3-5-sonnet-20241022")
- Compare different prompt variations and temperatures
- Test with structured inputs using template variables
- Automatically track cost and performance metrics

The tool creates a matrix of completions testing all combinations of models, prompts, inputs, and temperatures.

**Agent workflow:**
1. **Create experiments** using `playground` tool for testing
2. **Add results/conclusions** using `add_experiment_result` with:
   - Performance metrics (speed, cost, accuracy)
   - Key findings and insights
   - Recommendations for next steps
   - Model comparisons and winners
3. **Provide experiment URL** immediately for user review: `{{WEB_APP_URL}}/experiments/{experiment_id}`
4. **Check for user feedback** using `get_annotations`
5. **Iterate** based on feedback

Always add experiment results using `add_experiment_result` after completing any testing or analysis. This tool documents findings, performance metrics, and recommendations for future reference.

**Model selection for experiment creation:**
When creating experiments for agents with complex structured output schemas, asking **Claude Opus** to create the experiment is recommended. Less intelligent models have been known to modify or simplify schemas despite explicit instructions not to. Claude Opus consistently preserves the exact schema specifications as intended.

### Deployments

Deployments allow you to update an agent's prompt or model without changing the code. Learn more about deployments by reading the [Deployments](/deployments) page.

## `/v1/chat/completions`

### Parameters

Building an AI agent is the process of picking the right value for each parameter of the `/v1/chat/completions` API. Let's go through each parameter one by one.

<Tabs groupId="framework" items={['Python (OpenAI SDK)', 'TypeScript (OpenAI SDK)', 'Go (OpenAI SDK)']}>
<Tab value="Python (OpenAI SDK)">

```python
completion = client.chat.completions.create(  # or client.beta.chat.completions.parse for structured outputs
    model="..",
    messages=[...],
    metadata={
        "agent_id": "...",
        "key": "value", # user provided metadata
    },
    extra_body={
        # AnotherAI specific parameters
        "input": {
            "variable_name": "variable_value"
        },
    },
    max_tokens=1000,
)
print(completion.choices[0].message.content)
print(completion.choices[0].cost_usd)
print(completion.choices[0].duration_seconds)
```
</Tab>
<Tab value="TypeScript (OpenAI SDK)">
```typescript
const completion = await openai.chat.completions.create({
    model="..",
    messages=[...],
    metadata={
        "agent_id": "...",
        "key": "value", // user provided metadata
    }, 
    input: { // AnotherAI specific parameter. Might need to silence a TS error
        "variable_name": "variable_value"
        
    },
})
console.log(completion.choices[0].message.content)
console.log(completion.choices[0].cost_usd)
console.log(completion.choices[0].duration_seconds)
```
</Tab>

<Tab value="Go (OpenAI SDK)">
```go
params :=  openai.ChatCompletionNewParams{
    model: "..",
    metadata: map[string]string{
        "agent_id": "...",
        "key": "value", // user provided metadata
    },
}
params.SetExtraFields(map[string]any{
    "input": map[string]any{
        ...
    },
})
completion, err := client.Chat.Completions.New(context.TODO(), params)
fmt.Printf("Cost USD: %s", completion.choices[0].JSON.ExtraFields["cost_usd"].Raw())
fmt.Printf("Duration Seconds: %s", completion.choices[0].JSON.ExtraFields["duration_seconds"].Raw())
```
</Tab>
</Tabs>

#### model

One of the model.id from the `list_models` MCP tool, or `curl {{API_URL}}/v1/models`
AnotherAI allows non-OpenAI models to be used via a OpenAI SDK.
each model listed by AnotherAI includes information about its price, its intelligence (quality_index), its capabilities, its context window.


#### messages

`messages`: The messages to send to the model. The messages are a list of dictionaries, each dictionary containing a role and content. The role can be "user", "assistant", or "system". The content can be a string, or a list of strings.

```json
messages = [
    {"role": "user", "content": "Hello, how are you?"}
]
```

There are a few differences between the OpenAI API and AnotherAI API:
- **[Input variables](/observability/input-variables) (strongly recommended)**: Use Jinja2 template syntax to separate static instructions from dynamic data. This is a best practice that significantly improves observability, debugging, and prompt management.

```
messages=[{
    "role": "user", 
    "content": "Analyze this email: {{email_content}}"
}]
```

See the `input` parameter below on how to pass variables to the LLM. Note that the template rendering is done server-side by AnotherAI, so the client does not need to render the template.

Learn more about input variables by reading the [Input Variables](/observability/input-variables) section.

- [Deployments](/deployments): When using deployments, the `messages` parameter can be empty because the messages are stored on AnotherAI directly, and added automatically to the request. `messages = []` is valid. Note that the `messages` parameter is required by OpenAI SDKs, so `messages = None` is not valid.

Learn more about deployments by reading the [Deployments](/deployments) section.

#### metadata

Any key-value pair can be passed to the `metadata` parameter. Runs are searchable by metadata keys (list all the metadata keys for a given agent using the `query_completions` MCP tool). For example, "customer_id": "1234567890", "user_email": "john.doe@example.com".

> **Recommended**: Include `agent_id` in the `metadata` parameter to identify your agent and organize observability data. This is the preferred method for agent identification.

#### max_tokens

`max_tokens`: (optional) The maximum number of tokens to generate. If not provided, the model will generate as many tokens as needed. Make sure that `max_tokens` is high enough to generate a complete response.

#### input

`input`: (strongly recommended for most use cases) provides variables to the LLM when using [input variables](/observability/input-variables). **Always use input variables instead of string concatenation** when you have dynamic content - it dramatically improves debugging, observability, and prompt management.

<Tabs groupId="framework" items={['Python (OpenAI SDK)', 'TypeScript (OpenAI SDK)', 'Go (OpenAI SDK)']}>
<Tab value="Python (OpenAI SDK)">
```python
completion = client.chat.completions.create(
    messages=[{"role": "user", "content": "Analyze this email: {{email_content}}"}],
    extra_body={ # input must be wrapped in extra_body because the OpenAI SDK doesn't recognize 'input' as a valid parameter. extra_body passes custom fields directly to the request body.
        "input": {
            "email_content": "Dear team, please review the quarterly report..."
        }
    }
)
```
</Tab>
<Tab value="TypeScript (OpenAI SDK)">
```typescript
const completion = await openai.chat.completions.create({
    messages=[{"role": "user", "content": "Analyze this email: {{email_content}}"}],
    input: { // AnotherAI specific parameter. Might need to silence a TS error
        email_content: "Dear team, please review the quarterly report...",
    },
})
```
</Tab>
<Tab value="Go (OpenAI SDK)">
```go
params :=  openai.ChatCompletionNewParams{
    // OpenAI supported fields
}
// AnotherAI specific fields
params.SetExtraFields(map[string]any{
    "input": map[string]any{
        "email_content": "Dear team, please review the quarterly report...",
    },
})
```
</Tab>
</Tabs>



**Best practice:** Use input variables for any dynamic content rather than concatenating strings in your code. This separates your prompt logic from your application logic and makes debugging much easier.

#### response_format

`response_format`: (optional) ensures AI models generate responses that perfectly match your defined JSON Schema. Instead of hoping the model follows formatting instructions, you get guaranteed compliance with your data structure. Use structured outputs when you need reliable data extraction, classification, or any scenario requiring consistent JSON format.

<Tabs groupId="framework" items={['Python (OpenAI SDK)', 'TypeScript (OpenAI SDK)', 'Go (OpenAI SDK)']}>
<Tab value="Python (OpenAI SDK)">

```python
from pydantic import BaseModel

class UserInfo(BaseModel):
    name: str
    age: int
    email: str

completion = client.beta.chat.completions.parse(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Extract user info: John Doe, 30, john@example.com"}],
    response_format=UserInfo  # Guarantees valid UserInfo object
)

user = completion.choices[0].message.parsed  # Direct access to typed object
```

</Tab>
<Tab value="TypeScript (OpenAI SDK)">
```typescript
import { z } from "zod";
import { zodResponseFormat } from "openai/helpers/zod";

const UserInfo = z.object({
    name: z.string(),
    age: z.number(),
    email: z.string()
})

const completion = await openai.beta.chat.completions.parse({
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Extract user info: John Doe, 30, john@example.com"}],
    response_format: zodResponseFormat(UserInfo, "UserInfo"),
})

user = completion.output_parsed
```
</Tab>
<Tab value="Go (OpenAI SDK)">
```go
import "github.com/invopop/jsonschema"

type UserInfo struct {
    Name string `json:"name"`
    Age  int    `json:"age"`
    Email string `json:"email"`
}

UserInfoSchema := jsonschema.Reflect(&UserInfo{})

chatCompletion, err := client.Chat.Completions.New(context.TODO(), openai.ChatCompletionNewParams{
    Model: "autopilot-openai-beta-parse/" + model,
    Messages: ...,
    ResponseFormat: openai.ChatCompletionNewParamsResponseFormatUnion{
        OfJSONSchema: &openai.ResponseFormatJSONSchemaParam{
            JSONSchema: openai.ResponseFormatJSONSchemaJSONSchemaParam{
                Name:   "user_info",
                Schema: UserInfo,
            },
        },
    },
})
```
</Tab>
</Tabs>

Learn more about structured outputs in the [Structured Outputs](/inference/structured-outputs) section.

### Response

AnotherAI returns the same response format as the OpenAI API, ensuring full compatibility with existing code while adding additional fields for enhanced functionality.

<Tabs groupId="framework" items={['Python (OpenAI SDK)', 'TypeScript (OpenAI SDK)', 'Go (OpenAI SDK)']}>
<Tab value="Python (OpenAI SDK)">
```python
completion = client.chat.completions.create(...)
content = completion.choices[0].message.content

# for structured outputs
completion = client.beta.chat.completions.parse(..., response_format=...)
parsed_output = completion.choices[0].message.parsed
```
</Tab>
<Tab value="TypeScript (OpenAI SDK)">
```typescript
const completion = await openai.chat.completions.create(...)
const content = completion.choices[0].message.content
```
</Tab>
<Tab value="Go (OpenAI SDK)">
```go
completion, err := client.Chat.Completions.New(context.TODO(), openai.ChatCompletionNewParams{...})
if err != nil {
    ...
}
content := completion.Choices[0].Message.Content
```
</Tab>
</Tabs>

#### cost and latency

AnotherAI adds cost and latency to the response. Learn more about cost and latency in the [Cost Metadata](/inference/cost) section.

<Tabs groupId="framework" items={['Python (OpenAI SDK)', 'TypeScript (OpenAI SDK)', 'Go (OpenAI SDK)']}>
<Tab value="Python (OpenAI SDK)">
```python
cost = getattr(completion.choices[0], 'cost_usd', None)
latency = getattr(completion.choices[0], 'duration_seconds', None)
print(f"Latency (s): {latency:.2f}")
print(f"Cost   ($): ${cost:.6f}")
```
</Tab>
<Tab value="TypeScript (OpenAI SDK)">
```typescript
const cost = completion.choices[0].cost_usd
const latency = completion.choices[0].duration_seconds
console.log(`Cost: $${cost.toFixed(6)}`)
console.log(`Latency: ${latency.toFixed(2)}s`)
```
</Tab>
<Tab value="Go (OpenAI SDK)">
```go
completion, _ := client.Chat.Completions.New(context.TODO(), openai.ChatCompletionNewParams{...})
cost := strconv.ParseFloat(completion.Choices[0].JSON.ExtraFields["cost_usd"].Raw(), 32)
latency := strconv.ParseFloat(completion.Choices[0].JSON.ExtraFields["duration_seconds"].Raw(), 32)
fmt.Printf("Cost: $%f", cost)
fmt.Printf("Latency: %fs", latency)

```
</Tab>
</Tabs>

## URLs

AnotherAI provides direct URLs to view completions and experiments in the web app:

### Completion URL
To view a specific completion in the web app:
```
{{WEB_APP_URL}}/completions/{completion_id}
```

### Experiment URL
To view a specific experiment and its results:
```
{{WEB_APP_URL}}/experiments/{experiment_id}
```

### Query Results URL
When using the `query_completions` MCP tool, it returns a URL in this format:
```
{{WEB_APP_URL}}/completions?query={encoded_query}
```

This URL displays filtered completion results based on your SQL query.
